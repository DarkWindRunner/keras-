{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Training set images: train-images-idx3-ubyte.gz (9.9 MB, 解压后 47 MB, 包含 60,000 个样本)\n",
    "2. Training set labels: train-labels-idx1-ubyte.gz (29 KB, 解压后 60 KB, 包含 60,000 个标签)\n",
    "3. Test set images: t10k-images-idx3-ubyte.gz (1.6 MB, 解压后 7.8 MB, 包含 10,000 个样本)\n",
    "4. Test set labels: t10k-labels-idx1-ubyte.gz (5KB, 解压后 10 KB, 包含 10,000 个标签)\n",
    "5. 图像为28×28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#导入库\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 手动导入本地已经下载好的npz文件。npz文件是NumPy Zipped Data。本质就是多个数组。可以参考numpy.savez函数.用savez保存的时候可以用关键字给数组命名。\n",
    "2. 数组是以未压缩的原始二进制格式保存在扩展名为.npy的文件中。本质就是1个数组。可以参考numpy.save函数.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='/home/dashen/Downloads/mnist/mnist/mnist.npz'\n",
    "f = np.load(path)\n",
    "x_train, y_train = f['x_train'], f['y_train']\n",
    "x_test, y_test = f['x_test'], f['y_test']\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "显示一下读入的数据是什么样子的。\n",
    "1. x_train：是一个60000*28*28的矩阵。也就是60000个28*28的灰度图像。其中每个灰度值是0~255之间\n",
    "2. y_train：是60000个标签，标签值是0-9\n",
    "3. x_test：是一个10000*28*28的矩阵。也就是10000个28*28的灰度图像。其中每个灰度值是0~255之间\n",
    "4. y_test：是10000个标签，标签值是0-9\n",
    "5. 接下来我们试试看。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape (60000, 28, 28)\n",
      "x_train.size 47040000\n",
      "x_train[0] [[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
      "  175  26 166 255 247 127   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
      "  225 172 253 242 195  64   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
      "   93  82  82  56  39   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
      "   25   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
      "  150  27   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
      "  253 187   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
      "  253 249  64   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
      "  253 207   2   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
      "  250 182   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
      "   78   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n",
      "x_train[0].shape (28, 28)\n"
     ]
    }
   ],
   "source": [
    "#首先看一下x_train的数据。\n",
    "print('x_train.shape',x_train.shape)\n",
    "print('x_train.size',x_train.size)\n",
    "print('x_train[0]',x_train[0])\n",
    "print('x_train[0].shape',x_train[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>175</td>\n",
       "      <td>26</td>\n",
       "      <td>166</td>\n",
       "      <td>255</td>\n",
       "      <td>247</td>\n",
       "      <td>127</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>225</td>\n",
       "      <td>172</td>\n",
       "      <td>253</td>\n",
       "      <td>242</td>\n",
       "      <td>195</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>238</td>\n",
       "      <td>253</td>\n",
       "      <td>...</td>\n",
       "      <td>93</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>56</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>219</td>\n",
       "      <td>253</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>156</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>150</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>253</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>253</td>\n",
       "      <td>249</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>253</td>\n",
       "      <td>207</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>250</td>\n",
       "      <td>182</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>66</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>171</td>\n",
       "      <td>219</td>\n",
       "      <td>253</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>172</td>\n",
       "      <td>226</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>136</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>212</td>\n",
       "      <td>135</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0   1   2   3    4    5    6    7    8    9  ...   18   19   20   21   22  \\\n",
       "1    0   0   0   0    0    0    0    0    0    0 ...    0    0    0    0    0   \n",
       "2    0   0   0   0    0    0    0    0    0    0 ...    0    0    0    0    0   \n",
       "3    0   0   0   0    0    0    0    0    0    0 ...    0    0    0    0    0   \n",
       "4    0   0   0   0    0    0    0    0    0    0 ...    0    0    0    0    0   \n",
       "5    0   0   0   0    0    0    0    0    0    0 ...    0    0    0    0    0   \n",
       "6    0   0   0   0    0    0    0    0    0    0 ...  175   26  166  255  247   \n",
       "7    0   0   0   0    0    0    0    0   30   36 ...  225  172  253  242  195   \n",
       "8    0   0   0   0    0    0    0   49  238  253 ...   93   82   82   56   39   \n",
       "9    0   0   0   0    0    0    0   18  219  253 ...    0    0    0    0    0   \n",
       "10   0   0   0   0    0    0    0    0   80  156 ...    0    0    0    0    0   \n",
       "11   0   0   0   0    0    0    0    0    0   14 ...    0    0    0    0    0   \n",
       "12   0   0   0   0    0    0    0    0    0    0 ...    0    0    0    0    0   \n",
       "13   0   0   0   0    0    0    0    0    0    0 ...    0    0    0    0    0   \n",
       "14   0   0   0   0    0    0    0    0    0    0 ...    0    0    0    0    0   \n",
       "15   0   0   0   0    0    0    0    0    0    0 ...   25    0    0    0    0   \n",
       "16   0   0   0   0    0    0    0    0    0    0 ...  150   27    0    0    0   \n",
       "17   0   0   0   0    0    0    0    0    0    0 ...  253  187    0    0    0   \n",
       "18   0   0   0   0    0    0    0    0    0    0 ...  253  249   64    0    0   \n",
       "19   0   0   0   0    0    0    0    0    0    0 ...  253  207    2    0    0   \n",
       "20   0   0   0   0    0    0    0    0    0    0 ...  250  182    0    0    0   \n",
       "21   0   0   0   0    0    0    0    0    0    0 ...   78    0    0    0    0   \n",
       "22   0   0   0   0    0    0    0    0   23   66 ...    0    0    0    0    0   \n",
       "23   0   0   0   0    0    0   18  171  219  253 ...    0    0    0    0    0   \n",
       "24   0   0   0   0   55  172  226  253  253  253 ...    0    0    0    0    0   \n",
       "25   0   0   0   0  136  253  253  253  212  135 ...    0    0    0    0    0   \n",
       "26   0   0   0   0    0    0    0    0    0    0 ...    0    0    0    0    0   \n",
       "27   0   0   0   0    0    0    0    0    0    0 ...    0    0    0    0    0   \n",
       "28   0   0   0   0    0    0    0    0    0    0 ...    0    0    0    0    0   \n",
       "\n",
       "     23  24  25  26  27  \n",
       "1     0   0   0   0   0  \n",
       "2     0   0   0   0   0  \n",
       "3     0   0   0   0   0  \n",
       "4     0   0   0   0   0  \n",
       "5     0   0   0   0   0  \n",
       "6   127   0   0   0   0  \n",
       "7    64   0   0   0   0  \n",
       "8     0   0   0   0   0  \n",
       "9     0   0   0   0   0  \n",
       "10    0   0   0   0   0  \n",
       "11    0   0   0   0   0  \n",
       "12    0   0   0   0   0  \n",
       "13    0   0   0   0   0  \n",
       "14    0   0   0   0   0  \n",
       "15    0   0   0   0   0  \n",
       "16    0   0   0   0   0  \n",
       "17    0   0   0   0   0  \n",
       "18    0   0   0   0   0  \n",
       "19    0   0   0   0   0  \n",
       "20    0   0   0   0   0  \n",
       "21    0   0   0   0   0  \n",
       "22    0   0   0   0   0  \n",
       "23    0   0   0   0   0  \n",
       "24    0   0   0   0   0  \n",
       "25    0   0   0   0   0  \n",
       "26    0   0   0   0   0  \n",
       "27    0   0   0   0   0  \n",
       "28    0   0   0   0   0  \n",
       "\n",
       "[28 rows x 28 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#更加直观的输出，其实就是一个5\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "index=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28]\n",
    "fram1=DataFrame(x_train[0],index=index)\n",
    "fram1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train.shape (60000,)\n",
      "y_train.size 60000\n",
      "y_train[0] 5\n",
      "y_train[0].shape ()\n"
     ]
    }
   ],
   "source": [
    "#然后看一下y_train的数据。\n",
    "print('y_train.shape',y_train.shape)\n",
    "print('y_train.size',y_train.size)\n",
    "print('y_train[0]',y_train[0])\n",
    "print('y_train[0].shape',y_train[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_test.shape (10000, 28, 28)\n",
      "x_test.size 7840000\n",
      "x_test[0] [[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  84 185 159 151  60  36   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0 222 254 254 254 254 241 198 198 198 198 198 198\n",
      "  198 198 170  52   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  67 114  72 114 163 227 254 225 254 254 254 250\n",
      "  229 254 254 140   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  17  66  14  67  67  67  59\n",
      "   21 236 254 106   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   83 253 209  18   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  22\n",
      "  233 255  83   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 129\n",
      "  254 238  44   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  59 249\n",
      "  254  62   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 133 254\n",
      "  187   5   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   9 205 248\n",
      "   58   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 126 254 182\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  75 251 240  57\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  19 221 254 166   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3 203 254 219  35   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  38 254 254  77   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  31 224 254 115   1   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 133 254 254  52   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  61 242 254 254  52   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 121 254 254 219  40   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 121 254 207  18   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n",
      "x_test[0].shape (28, 28)\n"
     ]
    }
   ],
   "source": [
    "#第三看一下x_test的数据。\n",
    "print('x_test.shape',x_test.shape)\n",
    "print('x_test.size',x_test.size)\n",
    "print('x_test[0]',x_test[0])\n",
    "print('x_test[0].shape',x_test[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_test.shape (10000,)\n",
      "y_test.size 10000\n",
      "y_test[0] 7\n",
      "y_test[0].shape ()\n"
     ]
    }
   ],
   "source": [
    "#第四看一下y_test的数据。\n",
    "print('y_test.shape',y_test.shape)\n",
    "print('y_test.size',y_test.size)\n",
    "print('y_test[0]',y_test[0])\n",
    "print('y_test[0].shape',y_test[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7feceb8ed710>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#第五看一下图片的样子。\n",
    "plt.figure()\n",
    "plt.imshow(x_train[0], cmap='gray', interpolation='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#图片压平到1个数组内。并且把数据类型转化为浮点型，为了接下来归一化做准备。\n",
    "x_train = x_train.reshape(60000, 784).astype('float32')\n",
    "x_test = x_test.reshape(10000, 784).astype('float32')\n",
    "# 数据归一化\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape (60000, 784)\n",
      "x_train.size 47040000\n",
      "x_train[0] [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.01176471 0.07058824 0.07058824 0.07058824\n",
      " 0.49411765 0.53333336 0.6862745  0.10196079 0.6509804  1.\n",
      " 0.96862745 0.49803922 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.11764706 0.14117648 0.36862746 0.6039216\n",
      " 0.6666667  0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
      " 0.88235295 0.6745098  0.99215686 0.9490196  0.7647059  0.2509804\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.19215687\n",
      " 0.93333334 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
      " 0.99215686 0.99215686 0.99215686 0.9843137  0.3647059  0.32156864\n",
      " 0.32156864 0.21960784 0.15294118 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.07058824 0.85882354 0.99215686\n",
      " 0.99215686 0.99215686 0.99215686 0.99215686 0.7764706  0.7137255\n",
      " 0.96862745 0.94509804 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.3137255  0.6117647  0.41960785 0.99215686\n",
      " 0.99215686 0.8039216  0.04313726 0.         0.16862746 0.6039216\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.05490196 0.00392157 0.6039216  0.99215686 0.3529412\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.54509807 0.99215686 0.74509805 0.00784314 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.04313726\n",
      " 0.74509805 0.99215686 0.27450982 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.13725491 0.94509804\n",
      " 0.88235295 0.627451   0.42352942 0.00392157 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.31764707 0.9411765  0.99215686\n",
      " 0.99215686 0.46666667 0.09803922 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.1764706  0.7294118  0.99215686 0.99215686\n",
      " 0.5882353  0.10588235 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.0627451  0.3647059  0.9882353  0.99215686 0.73333335\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.9764706  0.99215686 0.9764706  0.2509804  0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.18039216 0.50980395 0.7176471  0.99215686\n",
      " 0.99215686 0.8117647  0.00784314 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.15294118 0.5803922\n",
      " 0.8980392  0.99215686 0.99215686 0.99215686 0.98039216 0.7137255\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.09411765 0.44705883 0.8666667  0.99215686 0.99215686 0.99215686\n",
      " 0.99215686 0.7882353  0.30588236 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.09019608 0.25882354 0.8352941  0.99215686\n",
      " 0.99215686 0.99215686 0.99215686 0.7764706  0.31764707 0.00784314\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.07058824 0.67058825\n",
      " 0.85882354 0.99215686 0.99215686 0.99215686 0.99215686 0.7647059\n",
      " 0.3137255  0.03529412 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.21568628 0.6745098  0.8862745  0.99215686 0.99215686 0.99215686\n",
      " 0.99215686 0.95686275 0.52156866 0.04313726 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.53333336 0.99215686\n",
      " 0.99215686 0.99215686 0.83137256 0.5294118  0.5176471  0.0627451\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.        ]\n",
      "x_train[0].shape (784,)\n"
     ]
    }
   ],
   "source": [
    "#再看一下x_train的数据。\n",
    "print('x_train.shape',x_train.shape)\n",
    "print('x_train.size',x_train.size)\n",
    "print('x_train[0]',x_train[0])\n",
    "print('x_train[0].shape',x_train[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义训练的数据，batch大小，epoch大小，最终分类的数量（num_classes）\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 3#20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n",
      "5\n",
      "0\n",
      "4\n",
      "1\n",
      "9\n",
      "2\n",
      "1\n",
      "3\n",
      "1\n",
      "4\n",
      "(60000, 10)\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "#目前y_train的数据还是0~9的数据分类。需要做成独热编码。比如现在是60000*1的数据标签，变成独热编码就是60000*10\n",
    "#显示一下独热编码之后的样子\n",
    "print(y_train.shape)\n",
    "for i in range(10):\n",
    "    print(y_train[i])\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "print(y_train.shape)\n",
    "for i in range(10):\n",
    "    print(y_train[i])\n",
    "    \n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# keras.utils.to_categorical(y, num_classes=None, dtype='float32')\n",
    "# 将类向量（整数）转换为二进制类矩阵\n",
    "# 将整型标签转为onehot。y为int数组，num_classes为标签类别总数，大于max(y)（标签从0开始的）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0901 11:15:38.697071 140656901809920 deprecation_wrapper.py:119] From /home/dashen/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0901 11:15:38.732794 140656901809920 deprecation_wrapper.py:119] From /home/dashen/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0901 11:15:38.739559 140656901809920 deprecation_wrapper.py:119] From /home/dashen/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0901 11:15:38.773168 140656901809920 deprecation_wrapper.py:119] From /home/dashen/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0901 11:15:38.789818 140656901809920 deprecation.py:506] From /home/dashen/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "#定义模型\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#显示模型的overview\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0901 11:15:38.919929 140656901809920 deprecation_wrapper.py:119] From /home/dashen/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0901 11:15:38.934464 140656901809920 deprecation_wrapper.py:119] From /home/dashen/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#编译模型，损失函数使用交叉熵\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0901 11:15:39.111230 140656901809920 deprecation.py:323] From /home/dashen/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 19s 314us/step - loss: 0.2549 - acc: 0.9207 - val_loss: 0.1283 - val_acc: 0.9588\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 19s 315us/step - loss: 0.1066 - acc: 0.9672 - val_loss: 0.0813 - val_acc: 0.9750\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 22s 363us/step - loss: 0.0780 - acc: 0.9758 - val_loss: 0.0791 - val_acc: 0.9765\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7feceb83c3c8>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#训练模型\n",
    "model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss on Test Set: 0.07908383468847606\n",
      "Accuracy of Testing Set: 0.9765\n"
     ]
    }
   ],
   "source": [
    "#模型的评估\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Total loss on Test Set:', score[0])\n",
    "print('Accuracy of Testing Set:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000,)\n",
      "(0,)\n",
      "[]\n",
      "(1,)\n",
      "[0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dashen/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: DeprecationWarning: elementwise == comparison failed; this will raise an error in the future.\n",
      "  after removing the cwd from sys.path.\n",
      "/home/dashen/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: DeprecationWarning: elementwise != comparison failed; this will raise an error in the future.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "#进行预测\n",
    "result = model.predict_classes(x_test)\n",
    "print(result.shape)\n",
    "correct_indices = np.nonzero(result == y_test)[0]\n",
    "print(correct_indices.shape)\n",
    "print(correct_indices)\n",
    "incorrect_indices = np.nonzero(result != y_test)[0]\n",
    "print(incorrect_indices.shape)\n",
    "print(incorrect_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#显示预测的结果\n",
    "plt.figure()\n",
    "for i, correct in enumerate(correct_indices[:9]):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.imshow(x_test[correct].reshape(28,28), cmap='gray', interpolation='none')\n",
    "    plt.title(\"Predicted {}, Class {}\".format(result[correct], y_test[correct]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "for i, incorrect in enumerate(incorrect_indices[:9]):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.imshow(x_test[incorrect].reshape(28,28), cmap='gray', interpolation='none')\n",
    "    plt.title(\"Predicted {}, Class {}\".format(result[incorrect], y_test[incorrect]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch 实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (hidden1): Linear(in_features=784, out_features=512, bias=True)\n",
      "  (hidden2): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (hidden3): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (predict): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dashen/anaconda3/lib/python3.7/site-packages/torch/jit/__init__.py:914: TracerWarning: Trace had nondeterministic nodes. Did you forget call .eval() on your model? Nodes:\n",
      "\t%input.3 : Float(60000, 512) = aten::dropout(%input.2, %19, %20), scope: Net # /home/dashen/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:806:0\n",
      "\t%input.5 : Float(60000, 512) = aten::dropout(%input.4, %27, %28), scope: Net # /home/dashen/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:806:0\n",
      "\t%input : Float(60000, 512) = aten::dropout(%input.6, %35, %36), scope: Net # /home/dashen/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:806:0\n",
      "This may cause errors in trace checking. To disable trace checking, pass check_trace=False to torch.jit.trace()\n",
      "  check_tolerance, _force_outplace, True, _module_class)\n",
      "/home/dashen/anaconda3/lib/python3.7/site-packages/torch/jit/__init__.py:914: TracerWarning: Output nr 1. of the traced function does not match the corresponding output of the Python function. Detailed error:\n",
      "Not within tolerance rtol=1e-05 atol=1e-05 at input[43892, 5] (-0.4258646070957184 vs. 0.2759397327899933) and 599963 other locations (99.00%)\n",
      "  check_tolerance, _force_outplace, True, _module_class)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round 0 tensor(2.3073, grad_fn=<NllLossBackward>)\n",
      "round 1 tensor(2.2583, grad_fn=<NllLossBackward>)\n",
      "round 2 tensor(2.2073, grad_fn=<NllLossBackward>)\n",
      "round 3 tensor(2.1485, grad_fn=<NllLossBackward>)\n",
      "round 4 tensor(2.0729, grad_fn=<NllLossBackward>)\n",
      "round 5 tensor(1.9728, grad_fn=<NllLossBackward>)\n",
      "round 6 tensor(1.8388, grad_fn=<NllLossBackward>)\n",
      "round 7 tensor(1.6692, grad_fn=<NllLossBackward>)\n",
      "round 8 tensor(1.4859, grad_fn=<NllLossBackward>)\n",
      "round 9 tensor(1.3165, grad_fn=<NllLossBackward>)\n",
      "round 10 tensor(1.1762, grad_fn=<NllLossBackward>)\n",
      "round 11 tensor(1.0617, grad_fn=<NllLossBackward>)\n",
      "round 12 tensor(0.9706, grad_fn=<NllLossBackward>)\n",
      "round 13 tensor(0.8978, grad_fn=<NllLossBackward>)\n",
      "round 14 tensor(0.8414, grad_fn=<NllLossBackward>)\n",
      "round 15 tensor(0.8111, grad_fn=<NllLossBackward>)\n",
      "round 16 tensor(0.8545, grad_fn=<NllLossBackward>)\n",
      "round 17 tensor(1.1677, grad_fn=<NllLossBackward>)\n",
      "round 18 tensor(1.4716, grad_fn=<NllLossBackward>)\n",
      "round 19 tensor(1.2847, grad_fn=<NllLossBackward>)\n",
      "round 20 tensor(1.3829, grad_fn=<NllLossBackward>)\n",
      "round 21 tensor(1.9446, grad_fn=<NllLossBackward>)\n",
      "round 22 tensor(2.2696, grad_fn=<NllLossBackward>)\n",
      "round 23 tensor(3.1203, grad_fn=<NllLossBackward>)\n",
      "round 24 tensor(2.2517, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2517)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from visdom import Visdom\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 3#20\n",
    "path='/home/dashen/Downloads/mnist/mnist/mnist.npz'\n",
    "f = np.load(path)\n",
    "x_train, y_train = f['x_train'], f['y_train']\n",
    "x_test, y_test = f['x_test'], f['y_test']\n",
    "f.close()\n",
    "\n",
    "x_train = x_train.reshape(60000, 784).astype('float32')\n",
    "x_test = x_test.reshape(10000, 784).astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "# y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "# y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "# 模型训练时提示 RuntimeError: multi-target not supported at\n",
    "# 其标签必须为0~n-1，而且必须为1维的，如果设置标签为[nx1]的，则也会出现以上错误。\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import tensorboard\n",
    "from torch.utils.tensorboard import SummaryWriter #pip install future\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self,n_feature,n_output):\n",
    "        super(Net, self).__init__()\n",
    "        self.hidden1 = nn.Linear(n_feature, 512)\n",
    "        self.hidden2 = nn.Linear(512, 512)\n",
    "        self.hidden3 = nn.Linear(512, 512)\n",
    "        self.predict = nn.Linear(512, n_output)\n",
    "    def forward(self, x):\n",
    "#         x=self.hidden1(x)\n",
    "#         x=torch.tanh(x)\n",
    "#         x=self.hidden2(x)\n",
    "#         x=torch.tanh(x)\n",
    "\n",
    "#         x=self.hidden1(x)\n",
    "#         x=torch.sigmoid(x)\n",
    "#         x=self.hidden2(x)\n",
    "#         x=torch.sigmoid(x)\n",
    "\n",
    "#         x=self.hidden1(x)\n",
    "#         x=torch.nn.functional.relu(x)\n",
    "#         x=torch.nn.functional.dropout(x,p = 0.5)\n",
    "#         x=self.hidden2(x)\n",
    "#         x=torch.nn.functional.relu(x)\n",
    "#         x=torch.nn.functional.dropout(x,p = 0.5)\n",
    "#         x=self.hidden3(x)\n",
    "#         x=torch.nn.functional.relu(x)\n",
    "#         x=torch.nn.functional.dropout(x,p = 0.5)        \n",
    "#         out = self.predict(x)\n",
    "        \n",
    "        x=self.hidden1(x)\n",
    "        x=torch.tanh(x)\n",
    "        x=torch.nn.functional.dropout(x,p = 0.5)\n",
    "        x=self.hidden2(x)\n",
    "        x=torch.tanh(x)\n",
    "        x=torch.nn.functional.dropout(x,p = 0.5)\n",
    "        x=self.hidden3(x)\n",
    "        x=torch.tanh(x)\n",
    "        x=torch.nn.functional.dropout(x,p = 0.5)        \n",
    "        out = self.predict(x)\n",
    "        return out\n",
    "\n",
    "input_feature=784\n",
    "output_feature=10\n",
    "net=Net(input_feature,output_feature)\n",
    "print(net)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.5)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "x_torch_train=torch.from_numpy(x_train)\n",
    "x_torch_test=torch.from_numpy(x_test)\n",
    "y_torch_train=torch.from_numpy(y_train).long()\n",
    "y_torch_test=torch.from_numpy(y_test).long()\n",
    "\n",
    "num_epochs = 25\n",
    "\n",
    "writer=SummaryWriter(comment=\"Mnist\",log_dir='/home/dashen/Desktop/MachineLearning/mnist')\n",
    "writer.add_graph(net,(x_torch_train,))\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    predition=net(x_torch_train)\n",
    "    loss=loss_func(predition,y_torch_train) #输入要是一个tensor\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print('round ' + str(epoch) + ' ' +str(loss))\n",
    "    writer.add_scalar(\"Train\",loss,epoch)\n",
    "writer.close()    \n",
    "print(loss.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorBoard 1.14.0 at http://dashen-PC:6006/ (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir=/home/dashen/Desktop/MachineLearning/mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dashen/anaconda3/lib/python3.7/site-packages/visdom/server.py:30: DeprecationWarning: zmq.eventloop.ioloop is deprecated in pyzmq 17. pyzmq now works with default tornado and asyncio eventloops.\n",
      "  ioloop.install()  # Needs to happen before any tornado imports!\n",
      "Checking for scripts.\n",
      "It's Alive!\n",
      "INFO:root:Application Started\n",
      "You can navigate to http://localhost:8097\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dashen/anaconda3/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/home/dashen/anaconda3/lib/python3.7/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/dashen/anaconda3/lib/python3.7/site-packages/visdom/server.py\", line 1308, in <module>\n",
      "    download_scripts_and_run()\n",
      "  File \"/home/dashen/anaconda3/lib/python3.7/site-packages/visdom/server.py\", line 1304, in download_scripts_and_run\n",
      "    main()\n",
      "  File \"/home/dashen/anaconda3/lib/python3.7/site-packages/visdom/server.py\", line 1299, in main\n",
      "    print_func=print_func, user_credential=user_credential)\n",
      "  File \"/home/dashen/anaconda3/lib/python3.7/site-packages/visdom/server.py\", line 1231, in start_server\n",
      "    ioloop.IOLoop.instance().start()\n",
      "  File \"/home/dashen/anaconda3/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 132, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/home/dashen/anaconda3/lib/python3.7/asyncio/base_events.py\", line 523, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/home/dashen/anaconda3/lib/python3.7/asyncio/base_events.py\", line 1722, in _run_once\n",
      "    event_list = self._selector.select(timeout)\n",
      "  File \"/home/dashen/anaconda3/lib/python3.7/selectors.py\", line 468, in select\n",
      "    fd_event_list = self._selector.poll(timeout, max_ev)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python -m visdom.server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
